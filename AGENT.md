# AGENT.md - AI Bradaa Contributor Guide
# World-Class Development Workflow & Architecture Reference

**Last Updated:** 2025-11-12 02:45 MYT (Asia/Kuala_Lumpur)
**Version:** 2.1
**Status:** Active - Phase 11 Brutal Stack Audit Complete
**Audience:** All AI agents and human developers contributing to AI Bradaa

---

## ğŸ”¥ CRITICAL: Phase 11 Brutal Stack Audit Complete

**NEW AUDIT REPORT:** See `PHASE_11_BRUTAL_STACK_AUDIT_2025_11_12.md` for comprehensive infrastructure analysis

**Key Findings (84-Mentor Council):**
- âœ… **Zero-cost stack VALIDATED** - Current architecture is excellent
- ğŸ”¥ **4 P0 Blockers identified** - Must fix before deployment:
  1. Add Google Gemini hard spend cap ($50)
  2. Warm Neon database (Netlify cron every 10 min)
  3. Add Upstash Redis for atomic rate limiting
  4. Move eval suite to GitHub Actions (2k min/mo)
- âœ… **Hybrid API Strategy approved** - Flash-Lite + Flash + Kimi K2 + Pro
- âœ… **MYR cost projections** - Free: RM0.04/user, Pro: RM5.32/user, Ultimate: RM106/user

**Composite Score:** 72/100 â†’ 94/100 (after P0 fixes) â†’ Target: â‰¥99/100

**Deployment Status:** ğŸ”´ BLOCKED until P0 fixes complete

---

## ğŸ¯ Purpose

This guide ensures every contributor (AI agent or human) works safely, consistently, and world-class on the AI Bradaa codebase. It mirrors and syncs with `ULTIMATE_CONSOLIDATED_AUDIT_REPORT.md` as the ultimate source of truth.

---

## ğŸ“‹ Table of Contents

1. [Quick Start](#quick-start)
2. [Architecture Overview](#architecture-overview)
3. [Core Systems](#core-systems)
4. [Development Workflow](#development-workflow)
5. [Quality Gates](#quality-gates)
6. [Safety Checklist](#safety-checklist)
7. [Code Standards](#code-standards)
8. [Testing Requirements](#testing-requirements)
9. [Deployment Process](#deployment-process)
10. [Common Pitfalls](#common-pitfalls)
11. [Resources](#resources)

---

## ğŸš€ Quick Start

### Before You Code

**CRITICAL: Read These First**
1. `/ULTIMATE_CONSOLIDATED_AUDIT_REPORT.md` - Architecture source of truth
2. `/CHANGELOG.md` - Development history (Phases 1-11)
3. `/README.md` - Project overview
4. This file (AGENT.md) - Workflow guide

### Environment Setup

```bash
# 1. Clone and navigate
cd /home/user/aibradaa

# 2. Install dependencies
npm install

# 3. Set up environment variables
cp .env.example .env
# Edit .env with required keys (see .env.example for all variables)

# 4. Verify setup
npm run test:smoke

# 5. Start development server
npm run dev
```

### Required Environment Variables

```bash
# Critical (Production-blocking)
GEMINI_API_KEY=required                    # Google AI Studio
GOOGLE_MAPS_API_KEY=required               # Google Cloud Console
JWT_SECRET=required                        # openssl rand -base64 32
PWA_VAPID_PUBLIC_KEY=required             # web-push generate-vapid-keys
PWA_VAPID_PRIVATE_KEY=required

# Gemini 2.5 Models
GEMINI_MODEL_FLASH=gemini-2.5-flash
GEMINI_MODEL_PRO=gemini-2.5-pro
GEMINI_MODEL_PRO_EXP=gemini-2.5-pro-exp

# Data Sync
DATA_SYNC_INTERVAL_MS=21600000             # 6 hours

# Rate Limiting
AI_RATE_LIMIT_FREE=10                      # req/min
AI_RATE_LIMIT_PRO=30
AI_RATE_LIMIT_ULTIMATE=60

# Daily Quotas
AI_QUOTA_FREE=100                          # req/day
AI_QUOTA_PRO=500
AI_QUOTA_ULTIMATE=2000

# Feature Flags
ENABLE_VOICE=true
ENABLE_VISION=true
ENABLE_MAPS=true
ENABLE_SEARCH_GROUNDING=true
ENABLE_THINKING_MODE=true
CATCHPHRASE_ENABLED=true

# Optional
GA4_TRACKING_ID=G-XXXXXXXXXX              # Google Analytics
SENTRY_DSN=                                # Error tracking
```

---

## ğŸ— Architecture Overview

### System Architecture (5 Main Systems)

```
AI Bradaa Ecosystem
â”‚
â”œâ”€â”€ 1. Syeddy Orchestrator (Internal - Development Team Use Only)
â”‚   â””â”€â”€ Oversees project execution with AI intelligence system
â”‚
â”œâ”€â”€ 2. AI Bradaa (PUBLIC - Main Product)
â”‚   â”œâ”€â”€ 7 PWA Tools (Matchmaker, Versus, Explorer, Command, Intel, Appendices, Camera Tech)
â”‚   â”œâ”€â”€ Gemini 2.5 Pro/Flash Integration
â”‚   â”œâ”€â”€ Voice, Vision, Maps Features
â”‚   â””â”€â”€ Three-Tier Pricing (Free RM0, Pro RM30, Ultimate RM80)
â”‚
â”œâ”€â”€ 3. ABO-84 Beta (PUBLIC - Ultimate Tier Only)
â”‚   â”œâ”€â”€ AI Coding Assistant (like Claude Code, Cursor)
â”‚   â”œâ”€â”€ Desktop Apps (Windows .exe, macOS .dmg, Linux .AppImage)
â”‚   â”œâ”€â”€ VS Code Extension
â”‚   â”œâ”€â”€ CLI Tool (npm install -g abo84-beta)
â”‚   â””â”€â”€ Ollama Integration (ollama install aibradaa/abo84-beta)
â”‚
â”œâ”€â”€ 4. AI Pod (Internal - Centralized AI Hub)
â”‚   â”œâ”€â”€ /ai_pod/personas/ - AI personality systems
â”‚   â”œâ”€â”€ /ai_pod/pipelines/ - TOON format, data processing
â”‚   â”œâ”€â”€ /ai_pod/adapters/ - Gemini adapters
â”‚   â”œâ”€â”€ /ai_pod/services/ - Catchphrase engine, RAG, etc.
â”‚   â””â”€â”€ /ai_pod/prototypes/ - Experimental features (soul_v1, deck_v2, thinking_v1)
â”‚
â””â”€â”€ 5. Syeddy Debugger (Internal - Owner Maintenance Only)
    â”œâ”€â”€ 300+ Signal Monitoring
    â”œâ”€â”€ Safe-Diff Patcher
    â””â”€â”€ 1-Click Update System
```

### Directory Structure (Source of Truth)

```
/home/user/aibradaa/
â”œâ”€â”€ /public/                  # Frontend (Deployed)
â”‚   â”œâ”€â”€ /app/                # 7 PWA tools (deployed versions)
â”‚   â”œâ”€â”€ /scripts/            # Core JS (app-core.js, ai-integration.js, etc.)
â”‚   â”œâ”€â”€ /icons/              # PWA icons (8 sizes)
â”‚   â”œâ”€â”€ /data/               # Frontend laptop data (217KB subset)
â”‚   â”œâ”€â”€ index.html           # Landing page
â”‚   â”œâ”€â”€ app.html             # Main PWA
â”‚   â””â”€â”€ manifest.json        # PWA manifest
â”‚
â”œâ”€â”€ /netlify/functions/      # Backend (Serverless)
â”‚   â”œâ”€â”€ command.mjs, chat.mjs, intel.mjs, deck.mjs
â”‚   â”œâ”€â”€ gemini-live.mjs, vision-analysis.mjs
â”‚   â”œâ”€â”€ stripe-webhook.mjs, auth.mjs
â”‚   â””â”€â”€ /utils/              # Shared utilities (gemini.mjs, quota.mjs, cache.mjs)
â”‚
â”œâ”€â”€ /ai_pod/                 # AI Centralization Hub (Internal)
â”‚   â”œâ”€â”€ /personas/           # AI personalities (syeddy_base_v2.3.0, command_*, catchphrases)
â”‚   â”œâ”€â”€ /pipelines/          # TOON format, data processing
â”‚   â”œâ”€â”€ /adapters/           # Gemini v2.5 adapter
â”‚   â”œâ”€â”€ /services/           # Auto-fetch, RAG, deep-research
â”‚   â””â”€â”€ /prototypes/         # Experimental (soul_v1, deck_v2, thinking_v1, branding_v1)
â”‚
â”œâ”€â”€ /data/                   # Master Data (Source of Truth)
â”‚   â”œâ”€â”€ laptops.json         # Master laptop database (348KB, 100 laptops)
â”‚   â””â”€â”€ quarantine/          # Invalid data
â”‚
â”œâ”€â”€ /database/               # PostgreSQL Schema
â”‚   â”œâ”€â”€ /schema/             # SQL schemas
â”‚   â”œâ”€â”€ /migrations/         # Database migrations
â”‚   â””â”€â”€ /repositories/       # Data access layer
â”‚
â”œâ”€â”€ /project/governance/84/  # Internal Governance (Development Team)
â”‚   â”œâ”€â”€ council_roster.json  # AI intelligence system profiles (193KB)
â”‚   â”œâ”€â”€ composite_score_nov_2025.md
â”‚   â”œâ”€â”€ policy_pdpa.md, policy_security.md
â”‚   â””â”€â”€ /eval_suites/        # Evaluation baselines
â”‚
â”œâ”€â”€ /abo-84-beta/            # ABO-84 Coding Assistant
â”‚   â”œâ”€â”€ /demo/               # Demo files
â”‚   â””â”€â”€ README.md            # Distribution guide
â”‚
â”œâ”€â”€ /syeddy-debugger/        # Owner Debugger (Internal)
â”‚   â””â”€â”€ /signals/            # 300+ monitoring signals
â”‚
â”œâ”€â”€ /tests/                  # Test Suites
â”‚   â”œâ”€â”€ /smoke/              # Smoke tests
â”‚   â”œâ”€â”€ /integration/        # Integration tests
â”‚   â”œâ”€â”€ /unit/               # Unit tests
â”‚   â””â”€â”€ /data/               # Data validation
â”‚
â”œâ”€â”€ /tools/                  # Build & Dev Tools
â”‚   â”œâ”€â”€ build.mjs, dev-server.mjs
â”‚   â””â”€â”€ /etl/                # Data extraction/transformation
â”‚
â”œâ”€â”€ /internal/               # Internal Documentation
â”‚   â””â”€â”€ /one-piece-reference/ # Tone guide (INTERNAL USE ONLY)
â”‚
â”œâ”€â”€ /archive/                # Deprecated Code (DO NOT USE)
â”‚   â”œâ”€â”€ /api/                # Deprecated Express API (use /netlify/functions/)
â”‚   â”œâ”€â”€ /documentation_2025-11-09/
â”‚   â””â”€â”€ /audit_reports_2025_11_09/
â”‚
â”œâ”€â”€ ULTIMATE_CONSOLIDATED_AUDIT_REPORT.md  # Architecture Source of Truth
â”œâ”€â”€ CHANGELOG.md             # Development history (Phases 1-11)
â”œâ”€â”€ README.md                # Project overview
â”œâ”€â”€ AGENT.md                 # This file
â”œâ”€â”€ package.json             # Dependencies & scripts
â”œâ”€â”€ netlify.toml             # Netlify deployment config
â””â”€â”€ .env.example             # Environment template
```

---

## ğŸ§© Core Systems

### System 1: Syeddy Orchestrator (Internal Use Only)

**Purpose:** Development team's AI intelligence system for project execution
**Location:** `/project/governance/84/`
**Public Exposure:** âŒ NONE - Keep internal

**Key Concepts:**
- AI-powered decision intelligence
- Composite scoring system (target: â‰¥99/100)
- Automated quality gates
- Never mention in public-facing code or documentation

**Internal Files:**
- `/project/governance/84/council_roster.json` - AI intelligence profiles (193KB)
- `/project/governance/84/composite_score_nov_2025.md` - Current quality score
- `/project/governance/84/lenses_catalog.json` - Decision analysis lenses
- `/project/governance/84/policy_pdpa.md` - PDPA compliance policy
- `/project/governance/84/policy_security.md` - Security policy

**Public Terminology:**
- Instead of "84-mentor council" â†’ Use "AI Bradaa Intelligence System"
- Instead of mentor names â†’ Use "AI Bradaa [Domain]" (e.g., "AI Bradaa Strategy")

---

### System 2: AI Bradaa (Main Public Product)

**Purpose:** Malaysia's first AI-powered laptop recommendation platform
**Location:** `/public/`
**Public Exposure:** âœ… FULL - Main product

**7 PWA Tools:**

1. **Matchmaker** - 5 questions â†’ 3 perfect laptop matches
2. **Versus Mode** - Compare 2-3 laptops with radar charts
3. **Explorer** - Browse Top 35 with smart filters
4. **AI Bradaa Command** - Natural language chat interface
5. **Intel Feed** - News, reviews, price drops
6. **Appendices** - Full Top-100 catalog with affiliate links
7. **Camera Tech** - Webcam specs for creators (Coming Q2 2025)

**Key Features:**
- Gemini 2.5 Pro/Flash AI integration
- Voice interface (Gemini Live API)
- Vision analysis (upload laptop photos)
- Google Maps integration (store locations)
- Offline-first PWA
- Push notifications
- Three-tier pricing (Free RM0, Pro RM30, Ultimate RM80)

**Tech Stack:**
- Frontend: Vanilla JS (ESM), HTML5, CSS3
- PWA: Service Worker, IndexedDB, Web App Manifest
- Backend: Netlify Serverless Functions
- AI: Google Gemini 2.5 Pro/Flash
- Maps: Google Maps JavaScript API + Places API
- Analytics: Google Analytics 4 (GDPR compliant)

---

### System 3: ABO-84 Beta (Advanced Coding Assistant)

**Purpose:** AI coding assistant for developers (like Claude Code, Cursor)
**Location:** `/abo-84-beta/`
**Public Exposure:** âœ… PARTIAL - Ultimate tier only (RM80/month)

**Distribution Methods:**

1. **Standalone Desktop App**
   - Windows: `.exe` installer
   - macOS: `.dmg` installer
   - Linux: `.AppImage` or Snap

2. **Ollama Integration**
   ```bash
   ollama install aibradaa/abo84-beta
   ```

3. **VS Code Extension**
   - Available on VS Code Marketplace
   - Integrated editor workflow
   - Inline suggestions + chat panel

4. **CLI Tool**
   ```bash
   npm install -g abo84-beta
   ```

**Access Control:**
- âŒ FREE Tier (RM0) - No access
- âŒ PRO Tier (RM30) - No access
- âœ… ULTIMATE Tier (RM80) - Full access

**Key Features:**
- AI intelligence-backed code reviews
- Real-time coding assistance
- Local LLM execution (privacy-focused via Ollama)
- No cloud dependencies option
- Terminal-based + IDE integration

---

### System 4: AI Pod (Internal AI Centralization Hub)

**Purpose:** Centralized AI logic, features, pipelines (Internal)
**Location:** `/ai_pod/`
**Public Exposure:** âŒ NONE - Internal only

**Sub-Systems:**

1. **Personas** (`/ai_pod/personas/`)
   - `syeddy_base_v2.3.0.md` - Base AI personality
   - `command_fast_v1.2.0.md` - Fast response mode (â‰¤1.2s latency)
   - `command_think_v1.0.0.md` - Deep reasoning mode
   - `one_piece_catchphrase_engine_v4.mjs` - Personality system (INTERNAL reference only)
   - Never expose One Piece references in public files

2. **Pipelines** (`/ai_pod/pipelines/`)
   - TOON format (30-60% token savings vs JSON)
   - Data processing workflows

3. **Adapters** (`/ai_pod/adapters/`)
   - `gemini_v2_5_adapter.mjs` - Gemini API integration

4. **Services** (`/ai_pod/services/`)
   - `catchphrase_auto_fetch.mjs` - Daily catchphrase refresh (3:00 AM MYT)
   - `deep_research.mjs` - Advanced RAG search
   - `rag_search.mjs` - Retrieval-augmented generation

5. **Prototypes** (`/ai_pod/prototypes/`)
   - `soul_v1/` - Ferrofluid state visualization
   - `deck_v2/` - 8-card response format
   - `thinking_v1/` - Typing/shimmer animations
   - `branding_v1/` - Logo, colors, typography

**Critical Rules:**
- âŒ Never import from `/ai_pod` in `/public` files
- âœ… Only `/netlify/functions` can import from `/ai_pod`
- âŒ Never expose internal AI logic to frontend

---

### System 5: Syeddy Debugger (Internal Owner Maintenance)

**Purpose:** Automated maintainer for owner debugging (Internal)
**Location:** `/syeddy-debugger/`
**Public Exposure:** âŒ NONE - Owner only

**Features:**
- 300+ monitoring signals
- Safe-diff patcher
- 1-click update system
- Never mention in public documentation

---

## ğŸ”„ Development Workflow

### Step 1: Planning

**Before writing code:**

1. **Check Existing Implementation**
   ```bash
   # Search for similar features
   grep -r "function_name" /home/user/aibradaa/
   ```

2. **Review Source of Truth**
   - Read `/ULTIMATE_CONSOLIDATED_AUDIT_REPORT.md` section for your feature
   - Check `/CHANGELOG.md` for related Phase implementations
   - Verify in `/project/governance/84/composite_score_nov_2025.md` for quality requirements

3. **Identify Impact Areas**
   - Frontend only? â†’ `/public/`
   - Backend only? â†’ `/netlify/functions/`
   - Full-stack? â†’ Both
   - AI-related? â†’ Must centralize in `/ai_pod/`

4. **Plan Quality Gates**
   - What tests are needed? (smoke/integration/unit)
   - What documentation updates?
   - What composite score impact?

---

### Step 2: Implementation

**Coding Standards:**

1. **File Placement** (CRITICAL)
   - âŒ NEVER create in `/api/` (deprecated, use `/netlify/functions/`)
   - âŒ NEVER create in `/Laptops/` (deprecated, use `/data/laptops.json`)
   - âŒ NEVER create in `/app/` (use `/public/app/` for deployed code)
   - âœ… Frontend: `/public/`
   - âœ… Backend: `/netlify/functions/`
   - âœ… AI Logic: `/ai_pod/`
   - âœ… Tests: `/tests/`
   - âœ… Tools: `/tools/`

2. **Module Pattern**
   ```javascript
   // âœ… Good: ES6 modules
   export function myFunction() { }
   import { helper } from './utils.mjs';

   // âŒ Bad: CommonJS in new code
   module.exports = { };
   const helper = require('./utils');
   ```

3. **Error Handling**
   ```javascript
   // âœ… Good: Try-catch with specific errors
   try {
     const result = await riskyOperation();
     return { success: true, data: result };
   } catch (error) {
     console.error('[FunctionName] Error:', error.message);
     return { success: false, error: error.message };
   }

   // âŒ Bad: Silent failures
   try {
     await riskyOperation();
   } catch (e) { }
   ```

4. **Environment Variables**
   ```javascript
   // âœ… Good: Validate required env vars
   const API_KEY = process.env.GEMINI_API_KEY;
   if (!API_KEY) {
     throw new Error('GEMINI_API_KEY is required');
   }

   // âŒ Bad: Silent undefined
   const API_KEY = process.env.GEMINI_API_KEY;
   await callAPI(API_KEY); // Will fail silently if undefined
   ```

5. **Rate Limiting** (All AI endpoints MUST have)
   ```javascript
   import { checkRateLimit } from '../utils/quota.mjs';

   export async function handler(event) {
     const userId = getUserId(event);
     const tier = await getUserTier(userId);

     const rateLimitCheck = await checkRateLimit(userId, tier, 'ai-endpoint');
     if (!rateLimitCheck.allowed) {
       return {
         statusCode: 429,
         body: JSON.stringify({ error: 'Rate limit exceeded' })
       };
     }

     // ... rest of handler
   }
   ```

---

### Step 3: Testing

**Required Tests (Per Type):**

| Code Type | Required Tests | Location |
|-----------|----------------|----------|
| Netlify Function | Integration test | `/tests/integration/` |
| Public UI | Smoke test | `/tests/smoke/` |
| Utility Function | Unit test | `/tests/unit/` |
| Data Change | Data validation | `/tests/data/` |

**Test Commands:**
```bash
# Run all tests
npm run test:all

# Smoke tests only (boot, CSP, render)
npm run test:smoke

# Data tests (schema, validation)
npm run test:data

# Integration tests (API endpoints)
npm run test:integration

# Unit tests
npm run test:unit
```

**Coverage Target:** â‰¥70% for production deployment

---

### Step 4: Documentation

**Required Documentation Updates:**

1. **Code Changes:**
   - Add JSDoc comments to all exported functions
   - Update README.md if public-facing feature
   - Update AGENT.md if workflow changes
   - Update ULTIMATE_CONSOLIDATED_AUDIT_REPORT.md if architectural change

2. **Example JSDoc:**
   ```javascript
   /**
    * Fetches laptop recommendations based on user preferences
    * @param {Object} preferences - User preferences
    * @param {string} preferences.budget - Budget range
    * @param {Array<string>} preferences.useCases - Use cases
    * @param {string} preferences.tier - User tier (free/pro/ultimate)
    * @returns {Promise<Object>} Recommendations result
    * @throws {Error} If Gemini API fails
    */
   export async function getRecommendations(preferences) {
     // ...
   }
   ```

3. **CHANGELOG.md Entry:**
   ```markdown
   ## Phase X - Feature Name (YYYY-MM-DD)

   **Commit:** `abc1234`
   **Lines Added/Modified:** XXX lines
   **Composite Score:** XX/100

   ### Implementation Summary
   [Brief description]

   ### Key Deliverables
   1. Feature A
   2. Feature B

   ### Files Created/Enhanced
   - /path/to/file.mjs (XXX lines)
   ```

---

## ğŸ›¡ Quality Gates

### Pre-Commit Checklist

**Before committing, verify:**

- [ ] No `console.log()` in production code (use proper logging)
- [ ] No placeholder values (e.g., `G-XXXXXXXXXX`, `YOUR_API_KEY`)
- [ ] No TODO comments in critical paths
- [ ] All imports resolve correctly
- [ ] No syntax errors (`node --check file.mjs`)
- [ ] No One Piece character names in public files
- [ ] No mentor names in public files
- [ ] All secrets in `.env` (not hardcoded)
- [ ] Rate limiting added to AI endpoints
- [ ] Error handling present
- [ ] Tests written and passing

---

### Pre-Deployment Checklist

**Before deploying to production:**

- [ ] All tests pass (`npm run test:all`)
- [ ] Composite score â‰¥99/100
- [ ] No blocking issues in governance review
- [ ] Environment variables set in Netlify
- [ ] Smoke tests pass on staging
- [ ] No PDPA compliance violations
- [ ] Cost ceiling enforced per tier
- [ ] SLO monitoring instrumented
- [ ] Rollback plan documented

---

## ğŸš¨ Safety Checklist

### Security Red Lines (NEVER violate)

1. **API Keys**
   - âŒ NEVER commit API keys to git
   - âŒ NEVER hardcode secrets in code
   - âœ… ALWAYS use environment variables
   - âœ… ALWAYS validate env vars on startup

2. **User Data**
   - âŒ NEVER log sensitive user data
   - âŒ NEVER store passwords in plaintext
   - âœ… ALWAYS use bcrypt for passwords
   - âœ… ALWAYS encrypt PII at rest

3. **PDPA Compliance**
   - âŒ NEVER collect data without consent
   - âŒ NEVER keep data beyond TTL
   - âœ… ALWAYS honor deletion requests
   - âœ… ALWAYS anonymize analytics

4. **Rate Limiting**
   - âŒ NEVER allow unlimited AI requests
   - âœ… ALWAYS enforce tier quotas
   - âœ… ALWAYS track token usage
   - âœ… ALWAYS cost ceiling enforcement

5. **Input Validation**
   - âŒ NEVER trust user input
   - âœ… ALWAYS sanitize inputs
   - âœ… ALWAYS validate against schema
   - âœ… ALWAYS escape outputs (XSS prevention)

---

### Legal Compliance

**One Piece References (CRITICAL):**
- âŒ NEVER use character names in public files (Luffy, Zoro, Nami, etc.)
- âŒ NEVER use direct quotes from episodes
- âŒ NEVER use trademarked terms (Straw Hat Pirates, etc.)
- âœ… OK in `/internal/one-piece-reference/` (internal use only)
- âœ… OK if 80%+ paraphrased and transformed

**Public Terminology:**
- Instead of "Luffy" â†’ Use "AI Bradaa"
- Instead of "Nakama" â†’ Use "teammate" or "friend"
- Instead of "Pirate King" â†’ Use "champion" or "leader"

---

## ğŸ“ Code Standards

### JavaScript/Node.js

**File Naming:**
- `.mjs` for ES6 modules (server-side)
- `.js` for browser JavaScript
- Use kebab-case for files: `data-sync.js` not `dataSync.js`

**Function Naming:**
```javascript
// âœ… Good: Descriptive, verb-first
async function fetchLaptopRecommendations(preferences) { }
function calculateCompositeScore(metrics) { }

// âŒ Bad: Unclear, noun-first
async function laptops(prefs) { }
function score(m) { }
```

**Async/Await:**
```javascript
// âœ… Good: Async/await with error handling
async function fetchData() {
  try {
    const response = await fetch(url);
    return await response.json();
  } catch (error) {
    console.error('[fetchData] Error:', error);
    throw error;
  }
}

// âŒ Bad: Promise chains
function fetchData() {
  return fetch(url)
    .then(r => r.json())
    .catch(e => console.error(e));
}
```

**Imports:**
```javascript
// âœ… Good: Explicit imports
import { getGeminiClient } from '../utils/gemini.mjs';
import { checkRateLimit } from '../utils/quota.mjs';

// âŒ Bad: Wildcard imports
import * as utils from '../utils.mjs';
```

---

### HTML/CSS

**HTML Structure:**
```html
<!-- âœ… Good: Semantic HTML5 -->
<section id="features">
  <h2>AI Bradaa Features</h2>
  <article class="feature-card">
    <h3>Matchmaker</h3>
    <p>Find your perfect laptop</p>
  </article>
</section>

<!-- âŒ Bad: Div soup -->
<div id="features">
  <div class="title">AI Bradaa Features</div>
  <div class="card">
    <div class="card-title">Matchmaker</div>
    <div>Find your perfect laptop</div>
  </div>
</div>
```

**CSS Classes:**
```css
/* âœ… Good: BEM-style naming */
.feature-card { }
.feature-card__title { }
.feature-card__description { }
.feature-card--highlighted { }

/* âŒ Bad: Generic, unclear */
.card { }
.title { }
.desc { }
```

---

### SQL/Database

**Schema Changes:**
```sql
-- âœ… Good: Migration with rollback
-- Migration 005_add_tier_column.sql
ALTER TABLE users ADD COLUMN tier VARCHAR(20) DEFAULT 'free';
CREATE INDEX idx_users_tier ON users(tier);

-- Rollback:
-- DROP INDEX idx_users_tier;
-- ALTER TABLE users DROP COLUMN tier;

-- âŒ Bad: Direct schema modification without migration
ALTER TABLE users ADD COLUMN tier VARCHAR(20);
```

**Queries:**
```javascript
// âœ… Good: Parameterized queries (SQL injection prevention)
const result = await db.query(
  'SELECT * FROM users WHERE email = $1',
  [email]
);

// âŒ Bad: String concatenation (SQL injection risk!)
const result = await db.query(
  `SELECT * FROM users WHERE email = '${email}'`
);
```

---

## ğŸ§ª Testing Requirements

### Test Coverage by Phase

| Phase | Test Type | Coverage Target | Status |
|-------|-----------|-----------------|--------|
| Pre-Production | Smoke | 100% critical paths | Required |
| Pre-Production | Integration | â‰¥70% API endpoints | Required |
| Pre-Production | Unit | â‰¥60% utilities | Recommended |
| Pre-Production | Data | 100% schema | Required |

### Writing Good Tests

**Smoke Test Example:**
```javascript
// tests/smoke/boot.test.mjs
import { test } from 'node:test';
import assert from 'node:assert';

test('Application boots without errors', async () => {
  const { default: app } = await import('../../api/server.mjs');
  assert.ok(app, 'App should export server instance');
});

test('Environment variables are set', () => {
  assert.ok(process.env.GEMINI_API_KEY, 'GEMINI_API_KEY required');
  assert.ok(process.env.JWT_SECRET, 'JWT_SECRET required');
});
```

**Integration Test Example:**
```javascript
// tests/integration/gemini.test.mjs
import { test } from 'node:test';
import assert from 'node:assert';
import { handler } from '../../netlify/functions/chat.mjs';

test('Chat endpoint returns valid response', async () => {
  const event = {
    body: JSON.stringify({ query: 'Best laptop under RM5000?' }),
    headers: { authorization: 'Bearer test-token' }
  };

  const response = await handler(event);
  assert.strictEqual(response.statusCode, 200);

  const body = JSON.parse(response.body);
  assert.ok(body.response, 'Should have response field');
  assert.ok(body.metadata, 'Should have metadata');
});
```

---

## ğŸš€ Deployment Process

### Deployment Workflow

```mermaid
graph LR
    A[Code Change] --> B[Run Tests]
    B --> C{Tests Pass?}
    C -->|No| A
    C -->|Yes| D[Update Docs]
    D --> E[Composite Score Check]
    E --> F{Score â‰¥99?}
    F -->|No| A
    F -->|Yes| G[Commit to Branch]
    G --> H[Push to Remote]
    H --> I[Create PR]
    I --> J[Netlify Preview]
    J --> K[Review & Approve]
    K --> L[Merge to Production Branch]
    L --> M[Netlify Production Deploy]
    M --> N[Verify Deployment]
```

### Deployment Commands

**Local Testing:**
```bash
# 1. Run all tests
npm run test:all

# 2. Build for production
npm run build

# 3. Test production build locally
netlify dev
```

**Staging Deployment:**
```bash
# Deploy to Netlify preview
netlify deploy

# Test preview URL
# https://[deploy-id]--aibradaa.netlify.app
```

**Production Deployment:**
```bash
# Deploy to production
netlify deploy --prod

# Verify deployment
curl https://aibradaa.com/api/health
```

**Environment Variables (Netlify Dashboard):**
1. Go to Netlify Dashboard â†’ Site Settings â†’ Environment Variables
2. Add all variables from `.env.example`
3. Restart deployment

---

## âš ï¸ Common Pitfalls

### 1. Using Deprecated /api Folder

**Problem:**
```javascript
// âŒ Wrong: Importing from deprecated /api
import { geminiAdapter } from '../../api/adapters/geminiAdapter.mjs';
```

**Solution:**
```javascript
// âœ… Correct: Use /netlify/functions/utils
import { getGeminiClient } from '../utils/gemini.mjs';
```

---

### 2. Forgetting Rate Limits

**Problem:**
```javascript
// âŒ Wrong: No rate limiting
export async function handler(event) {
  const { query } = JSON.parse(event.body);
  const response = await callGeminiAPI(query);
  return { statusCode: 200, body: JSON.stringify(response) };
}
```

**Solution:**
```javascript
// âœ… Correct: Rate limit check
import { checkRateLimit } from '../utils/quota.mjs';

export async function handler(event) {
  const userId = getUserId(event);
  const tier = await getUserTier(userId);

  const rateCheck = await checkRateLimit(userId, tier, 'ai-chat');
  if (!rateCheck.allowed) {
    return { statusCode: 429, body: JSON.stringify({ error: 'Rate limit exceeded' }) };
  }

  const { query } = JSON.parse(event.body);
  const response = await callGeminiAPI(query);
  return { statusCode: 200, body: JSON.stringify(response) };
}
```

---

### 3. Hardcoding API Keys

**Problem:**
```javascript
// âŒ CRITICAL: Hardcoded API key (security risk!)
const GEMINI_API_KEY = 'AIzaSyXXXXXXXXXXXXXXXXXXXXXXXXXXXXX';
```

**Solution:**
```javascript
// âœ… Correct: Environment variable
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
if (!GEMINI_API_KEY) {
  throw new Error('GEMINI_API_KEY environment variable is required');
}
```

---

### 4. Exposing Internal AI Logic

**Problem:**
```javascript
// âŒ Wrong: Importing from /ai_pod in frontend
import { getGeminiClient } from '../../../ai_pod/adapters/gemini_v2_5_adapter.mjs';
```

**Solution:**
```javascript
// âœ… Correct: Frontend calls backend API, backend imports from /ai_pod
// Frontend (public/scripts/ai-integration.js)
const response = await fetch('/api/chat', {
  method: 'POST',
  body: JSON.stringify({ query })
});

// Backend (netlify/functions/chat.mjs)
import { getGeminiClient } from '../../ai_pod/adapters/gemini_v2_5_adapter.mjs';
```

---

### 5. Forgetting to Update CHANGELOG.md

**Problem:**
You implemented a feature but didn't document it in CHANGELOG.md

**Solution:**
After every significant change, add entry to CHANGELOG.md:
```markdown
## Phase X.Y - Feature Name (2025-MM-DD)

**Commit:** `[commit-hash]`
**Lines Added:** XXX

### Implementation
- Feature A implemented
- Feature B enhanced

### Files Modified
- /path/to/file.mjs (+XXX lines)
```

---

## ğŸ“š Resources

### Documentation Hierarchy (Read in Order)

1. **ULTIMATE_CONSOLIDATED_AUDIT_REPORT.md** - Architecture source of truth (12,825 lines)
2. **CHANGELOG.md** - Development history (Phases 1-11)
3. **AGENT.md** (this file) - Contributor workflow guide
4. **README.md** - Project overview
5. **Phase-specific docs:**
   - `/PHASE-9.20-IMPLEMENTATION-SUMMARY.md` - Semantic routing
   - `/SEMANTIC-ROUTING-QUICKSTART.md` - Auto-routing guide
   - `/INFRASTRUCTURE_SUITE_SUMMARY.md` - Infrastructure overview

### Key Configuration Files

- **/.env.example** - Environment variables template
- **/netlify.toml** - Netlify deployment config
- **/package.json** - Dependencies & scripts
- **/public/manifest.json** - PWA configuration

### Internal Documentation

- **/internal/one-piece-reference/README.md** - Personality tone guide (INTERNAL ONLY)
- **/project/governance/84/policy_pdpa.md** - PDPA compliance
- **/project/governance/84/policy_security.md** - Security policies

### External Resources

- **Gemini API Docs:** https://ai.google.dev/docs
- **Netlify Functions:** https://docs.netlify.com/functions/overview/
- **PWA Docs:** https://web.dev/progressive-web-apps/
- **Google Maps API:** https://developers.google.com/maps/documentation

---

## ğŸ“‹ 7-PHASE IMPLEMENTATION PLAN (Based on November 2025 Repo Audit)

**Last Updated:** 2025-11-12
**Status:** Active Roadmap
**Audit Score:** 6.5/10 (Reality Check - See Comprehensive Codebase Analysis)

This section documents the systematic plan to fix the 10 critical gaps identified in the brutally honest repo audit.

---

### **PHASE 1: Fix Data Pipeline (P0 - CRITICAL)**
**Status:** ğŸ”´ BLOCKED - ETL Returns 0 Items
**Estimated Effort:** 3-5 days
**Assigned To:** Backend Team

**Problem:**
- `/tools/etl/pipeline.mjs` - All fetchers return empty arrays `[]`
- `fetchShopee()` (line 86-88) - PLACEHOLDER
- `fetchLazada()` (line 90-94) - PLACEHOLDER
- `fetchOEM()` (line 97-100) - PLACEHOLDER
- `/ai_pod/services/laptop_auto_fetch.mjs` - Lines 197-232 are stubs

**Impact:** Extended catalog empty, no fresh data, manual curation only

**Fix Checklist:**
- [ ] Implement real Shopee scraper (Playwright/Puppeteer)
- [ ] Implement real Lazada API integration
- [ ] Implement real OEM site scrapers (Dell, HP, Lenovo, ASUS)
- [ ] Add retry logic with exponential backoff
- [ ] Add validation against schema before ingestion
- [ ] Test with real runs (fetch >0 laptops)
- [ ] Schedule weekly ETL via cron (Netlify Scheduled Functions)
- [ ] Update `/data/laptops-extended.json` (currently 0 items)

**Success Criteria:**
- ETL returns â‰¥50 laptops per run
- Data passes AJV schema validation
- Weekly automated runs successful for 3 consecutive weeks

---

### **PHASE 2: Connect Frontend to Real Data (P0 - CRITICAL)**
**Status:** ğŸ”´ BROKEN - Using Mock/Hardcoded Data
**Estimated Effort:** 2-3 days
**Assigned To:** Frontend Team

**Problem:**
- `explorer-search.mjs` generates 100 mock laptops in-memory (line 27-68)
- `matchmaker-recommend.mjs` uses 8 hardcoded laptops (line 26-115)
- `intel.mjs` returns hardcoded trends (line 24-26)
- Functions ignore `/data/laptops.json` (100 real laptops available!)

**Impact:** Users see fake data, not real Malaysian laptop market

**Fix Checklist:**
- [ ] Update `explorer-search.mjs` to read from `/data/laptops.json`
- [ ] Update `matchmaker-recommend.mjs` to use real database
- [ ] Update `intel.mjs` to fetch real trending topics (web scraping or API)
- [ ] Remove all hardcoded laptop arrays
- [ ] Add database connection to Netlify Functions
- [ ] Verify with end-to-end test (search returns real laptop names)

**Success Criteria:**
- Explorer shows real laptops from database
- Matchmaker recommends from full 100-laptop catalog
- Intel feed shows real market trends (not "RTX 4060", "16GB RAM")

---

### **PHASE 3: Optimize RAG Search (P1 - HIGH)**
**Status:** âš ï¸ INEFFICIENT - Computes Embeddings On-The-Fly
**Estimated Effort:** 2 days
**Assigned To:** AI Team

**Problem:**
- `rag-search.mjs` computes embeddings for EVERY search request
- No pre-computed vector database
- Will be slow with 100+ laptops (each search = 100+ Gemini API calls)

**Impact:** High latency, high cost, poor UX

**Fix Checklist:**
- [ ] Pre-compute embeddings for all laptops (batch job)
- [ ] Store embeddings in PostgreSQL (pgvector extension) or JSON cache
- [ ] Update `rag-search.mjs` to use cached embeddings
- [ ] Add incremental update (re-embed only changed laptops)
- [ ] Measure latency before/after (target: <500ms)

**Success Criteria:**
- RAG search completes in <500ms (p95)
- Embedding API calls reduced by 99%
- Cost per search <RM0.01

---

### **PHASE 4: Real Mentor LLM Calls (P1 - HIGH)**
**Status:** âš ï¸ SIMULATED - Hardcoded Responses
**Estimated Effort:** 3-4 days
**Assigned To:** AI Governance Team

**Problem:**
- `mentor-consultation.mjs` has real semantic routing
- BUT: Mentor responses are SIMULATED (lines 109-134)
- Uses hardcoded responses, not real LLM calls per mentor persona
- Current `syeddy_orchestrator.mjs` voting is randomized (lines 649-687)

**Impact:** "84-mentor governance" is theater, not real AI decision-making

**Fix Checklist:**
- [ ] Extract all 84 mentor profiles from DOC 1 (thinking styles, lenses, playbooks)
- [ ] Rebuild `_getMentorVote()` in `syeddy_orchestrator.mjs` to use:
  - [ ] Mentor's thinking style
  - [ ] Mentor's top lenses (wont-do, moat, prfaq, etc.)
  - [ ] Mentor's risk appetite (Low/Balanced/Medium-high)
  - [ ] Mentor's crisis posture
- [ ] For `mentor-consultation.mjs`, call Gemini with mentor persona prompts
- [ ] Add mentor response caching (same question = cached response)
- [ ] Test with 10 diverse decisions, verify mentor personalities differ

**Success Criteria:**
- Warren Buffett's responses focus on "wont-do" and "moat" lenses
- Elon Musk's responses focus on speed and risk-taking
- Max Schrems' responses focus on privacy and PDPA compliance
- Voting patterns match mentor risk appetites

---

### **PHASE 5: Implement Dissent Ledger (P1 - HIGH)**
**Status:** ğŸ“ DOCUMENTED BUT NOT IMPLEMENTED
**Estimated Effort:** 1 day
**Assigned To:** Governance Team

**Problem:**
- Dissent ledger described in DOC 1 (line 1245-1257)
- File doesn't exist: `ai_pod/governance/dissent_ledger.jsonl`
- No tracking of productive tension between mentors

**Impact:** No governance audit trail, no learning from mentor disagreements

**Fix Checklist:**
- [ ] Create `/project/governance/84/dissent-ledger.jsonl`
- [ ] Add append-only write to `_archiveDecision()` in Syeddy Orchestrator
- [ ] Format: `{timestamp, decision_id, mentor_a, mentor_a_position, mentor_b, mentor_b_position, tension, resolution, composite_score}`
- [ ] Add JSONL reader for governance analytics
- [ ] Add CI check: New ADRs must log dissent if mentors disagree

**Success Criteria:**
- Ledger captures Warren Buffett vs Elon Musk tensions (Cost vs Speed)
- Ledger captures Max Schrems vs Brian Balfour tensions (Privacy vs Growth)
- SHA256 digest included in export provenance

---

### **PHASE 6: Improve Test Coverage (P2 - MEDIUM)**
**Status:** âš ï¸ MINIMAL - Only 15% Coverage
**Estimated Effort:** 4-5 days
**Assigned To:** QA Team

**Problem:**
- `/tests/integration/netlify-functions.test.mjs` only checks if functions import
- No real API call tests
- No end-to-end tests
- No RAG accuracy tests
- No database integration tests

**Impact:** High risk of regressions, bugs slip into production

**Fix Checklist:**
- [ ] Write integration tests for all 10 Netlify functions
- [ ] Test real Gemini API calls (use test API key)
- [ ] Test database queries (use test database)
- [ ] Write RAG accuracy tests (golden set eval)
- [ ] Write end-to-end tests with Playwright
- [ ] Target: â‰¥70% code coverage

**Success Criteria:**
- Test coverage â‰¥70%
- All critical paths tested (auth, AI calls, database writes)
- CI fails if coverage drops below 70%

---

### **PHASE 7: Fix Composite Score Calculation (P2 - MEDIUM)**
**Status:** âš ï¸ CLAIMED 99/100, ACTUAL UNKNOWN
**Estimated Effort:** 2 days
**Assigned To:** Governance Team

**Problem:**
- README claims "Composite Score: 99.1/100"
- CHANGELOG claims "Composite Score: 99.5/100"
- No automated calculation script found
- Brutally honest audit suggests real score is ~65/100

**Impact:** False confidence, potential production issues

**Fix Checklist:**
- [ ] Create `/project/governance/84/calculate-composite-score.mjs`
- [ ] Implement scoring algorithm from DOC 1
- [ ] Factors: Code quality, test coverage, PDPA compliance, performance, security
- [ ] Run automated calculation
- [ ] Update README/CHANGELOG with REAL score
- [ ] Add CI check: Block merge if score <85/100

**Success Criteria:**
- Automated script calculates score from measurable metrics
- Score matches manual audit
- Score improves after Phases 1-6 implemented

---

### **Priority Order:**

**THIS WEEK (P0):**
1. Phase 1: Fix ETL Pipeline (returns 0 items)
2. Phase 2: Connect Frontend to Real Data (using mocks)

**NEXT WEEK (P1):**
3. Phase 3: Optimize RAG Search (slow/expensive)
4. Phase 4: Real Mentor LLM Calls (simulated)
5. Phase 5: Implement Dissent Ledger (missing)

**THIS MONTH (P2):**
6. Phase 6: Improve Test Coverage (15% â†’ 70%)
7. Phase 7: Fix Composite Score (claimed vs actual)

---

### **Brutal Truth Tracker:**

| Component | Claimed Status | Actual Status | Gap |
|-----------|----------------|---------------|-----|
| ETL Pipeline | "Functional" | Returns 0 items | ğŸ”´ FAKE |
| Explorer Search | "Functional" | Uses mock data | ğŸ”´ FAKE |
| Matchmaker | "Functional" | 8 hardcoded laptops | ğŸ”´ FAKE |
| Intel Feed | "Functional" | Hardcoded trends | ğŸ”´ FAKE |
| 84-Mentor Governance | "Fully implemented" | Simulated voting | âš ï¸ PARTIAL |
| RAG Search | "Functional" | Inefficient | âš ï¸ WORKS BUT SLOW |
| Versus AI | "Functional" | Real Gemini integration | âœ… REAL |
| Deep Research | "Functional" | Real multi-step AI | âœ… REAL |
| Database Schema | "Production-ready" | Comprehensive | âœ… REAL |
| Frontend Structure | "Complete" | All HTML/JS exists | âœ… REAL |
| Composite Score | "99.5/100" | Unknown (estimated ~65) | âš ï¸ UNVERIFIED |

**Overall Reality Score: 6.5/10** - Good infrastructure, incomplete execution.

---

## ğŸ¯ Success Criteria

### Your contribution is ready when:

- [ ] Code follows all standards in this guide
- [ ] All tests pass (`npm run test:all`)
- [ ] Documentation updated (CHANGELOG.md, README.md if needed)
- [ ] No security violations (see Safety Checklist)
- [ ] No PDPA violations
- [ ] Composite score impact calculated and acceptable
- [ ] PR description explains changes clearly
- [ ] Deployment verified on Netlify preview

---

## ğŸ† Quality Pledge

By contributing to AI Bradaa, you commit to:

1. **World-Class Quality** - Every line of code meets production standards
2. **Security First** - No compromises on security or privacy
3. **User Trust** - PDPA compliance and transparency
4. **Team Efficiency** - Clear documentation, no technical debt
5. **Continuous Improvement** - Learn from feedback, iterate

---

**Version:** 2.0
**Last Updated:** 2025-11-11
**Maintained By:** AI Bradaa Development Team
**Status:** Active

**For Questions:** Refer to ULTIMATE_CONSOLIDATED_AUDIT_REPORT.md or consult development team.

---

# Welcome to AI Bradaa Development! ğŸš€

Let's build world-class software together.

<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ABO-84 Ollama Integration | 100% Offline AI Code Analysis</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700;900&family=Share+Tech+Mono&family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../styles/cyberpunk-core.css">
    <link rel="stylesheet" href="../styles/landing-enhanced.css">
    <link rel="stylesheet" href="../styles/mobile-first.css">
    <style>
        .platform-hero{padding:120px 20px 60px;text-align:center}.platform-icon-large{font-size:5rem;margin-bottom:20px}.step-by-step{max-width:900px;margin:60px auto}.step{background:rgba(16,20,30,0.7);border:1px solid rgba(168,178,204,0.1);border-radius:16px;padding:30px;margin-bottom:30px}.step-number{display:inline-flex;align-items:center;justify-content:center;width:40px;height:40px;background:linear-gradient(135deg,#00F0FF,#0099CC);color:#010409;border-radius:50%;font-weight:900;font-size:1.2rem;margin-bottom:15px;font-family:'Orbitron',sans-serif}.step h3{color:#fff;margin-bottom:15px;font-family:'Orbitron',sans-serif}.step p{color:#A8B2CC;line-height:1.8}.code-block{background:rgba(0,0,0,0.5);border:1px solid rgba(0,240,255,0.2);border-radius:8px;padding:15px;margin:15px 0;font-family:'Share Tech Mono',monospace;color:#00F0FF;overflow-x:auto}.info-box{background:rgba(0,240,255,0.1);border-left:4px solid #00F0FF;padding:20px;margin:20px 0;border-radius:8px;color:#A8B2CC}.benefit-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(250px,1fr));gap:20px;margin:30px 0}.benefit-card{background:rgba(0,240,255,0.05);border:1px solid rgba(0,240,255,0.2);border-radius:12px;padding:20px;text-align:center}.benefit-card .icon{font-size:3rem;margin-bottom:15px}.benefit-card h4{color:#00F0FF;margin-bottom:10px;font-family:'Orbitron',sans-serif}.benefit-card p{color:#A8B2CC;font-size:0.9rem;line-height:1.7}
    </style>
</head>
<body>
    <div class="aurora-bg"></div>
    <div class="grid-overlay"></div>
    <header class="site-header">
        <div class="container">
            <div class="header-content">
                <div class="brand">
                    <img src="/icons/icon-192.png" alt="AI Bradaa" class="brand-icon" width="40" height="40">
                    <span class="brand-name font-display">AI Bradaa</span>
                </div>
                <div class="header-actions">
                    <a href="abo84.html" class="btn btn-secondary">‚Üê All Downloads</a>
                </div>
            </div>
        </div>
    </header>
    <main>
        <section class="platform-hero">
            <div class="container">
                <div class="platform-icon-large">ü§ñ</div>
                <h1 style="font-size:3rem;color:#fff;font-family:'Orbitron',sans-serif;margin-bottom:20px">ABO-84 Ollama Integration</h1>
                <p style="color:#A8B2CC;font-size:1.2rem;margin-bottom:30px">100% offline local LLM for privacy-focused code analysis. No internet required.</p>
                <div style="background:rgba(0,240,255,0.1);border-left:4px solid #00F0FF;padding:20px;margin:20px auto;border-radius:8px;color:#A8B2CC;max-width:700px"><strong>Requirements:</strong> Ollama 0.1.0+ | 8GB RAM (16GB recommended) | GPU recommended for faster analysis | ~3.5GB disk space</div>
            </div>
        </section>
        <section style="max-width:900px;margin:60px auto;padding:0 20px">
            <div class="container">
                <h2 style="text-align:center;color:#fff;font-family:'Orbitron',sans-serif;font-size:2.5rem;margin-bottom:40px">Why Ollama?</h2>
                <div class="benefit-grid">
                    <div class="benefit-card">
                        <div class="icon">üîí</div>
                        <h4>100% Private</h4>
                        <p>Your code never leaves your machine. Perfect for sensitive or proprietary codebases.</p>
                    </div>
                    <div class="benefit-card">
                        <div class="icon">‚úàÔ∏è</div>
                        <h4>Fully Offline</h4>
                        <p>No internet connection required. Analyze code anywhere, anytime.</p>
                    </div>
                    <div class="benefit-card">
                        <div class="icon">‚ö°</div>
                        <h4>Fast & Local</h4>
                        <p>Zero network latency. Analysis happens instantly on your hardware.</p>
                    </div>
                    <div class="benefit-card">
                        <div class="icon">üí∞</div>
                        <h4>No API Costs</h4>
                        <p>No per-request charges. Unlimited analysis included with Ultimate tier.</p>
                    </div>
                </div>
            </div>
        </section>
        <section class="step-by-step">
            <div class="container">
                <h2 style="text-align:center;color:#fff;font-family:'Orbitron',sans-serif;font-size:2.5rem;margin-bottom:40px">Installation Guide</h2>
                <div class="step">
                    <div class="step-number">1</div>
                    <h3>Install Ollama</h3>
                    <p>First, install Ollama on your system:</p>
                    <div class="code-block">
# macOS/Linux:<br>
curl https://ollama.ai/install.sh | sh<br>
<br>
# Windows:<br>
# Download from https://ollama.ai/download/windows
                    </div>
                    <p>Verify installation:</p>
                    <div class="code-block">
ollama --version<br>
# Should show: Ollama version 0.1.0 or higher
                    </div>
                </div>
                <div class="step">
                    <div class="step-number">2</div>
                    <h3>Download ABO-84 Model</h3>
                    <p>Install the ABO-84 model (requires Ultimate tier authentication):</p>
                    <div class="code-block">
ollama pull aibradaa/abo84-beta
                    </div>
                    <div class="info-box">
                        <strong>üì¶ Download Size:</strong> ~3.5GB. This may take 10-30 minutes depending on your connection speed. This is a one-time download.
                    </div>
                    <p>The model will be downloaded and cached locally at:</p>
                    <div class="code-block">
# macOS/Linux: ~/.ollama/models/<br>
# Windows: %USERPROFILE%\.ollama\models\
                    </div>
                </div>
                <div class="step">
                    <div class="step-number">3</div>
                    <h3>Verify Model Installation</h3>
                    <div class="code-block">
ollama list<br>
<br>
# Should show:<br>
# NAME                  SIZE     MODIFIED<br>
# aibradaa/abo84-beta   3.5GB    2 minutes ago
                    </div>
                </div>
                <div class="step">
                    <div class="step-number">4</div>
                    <h3>Test the Model</h3>
                    <p>Run a quick test to ensure everything works:</p>
                    <div class="code-block">
ollama run aibradaa/abo84-beta "Analyze this code: function test() { eval('alert(1)') }"<br>
<br>
# Expected output:<br>
# Security Issue Detected: SEC-001<br>
# eval() usage creates security vulnerability<br>
# Severity: CRITICAL<br>
# Recommendation: Remove eval() and use safe alternatives
                    </div>
                </div>
                <div class="step">
                    <div class="step-number">5</div>
                    <h3>Integrate with ABO-84 CLI</h3>
                    <p>Configure ABO-84 to use the local Ollama model:</p>
                    <div class="code-block">
# Set Ollama as default engine<br>
abo84 config set engine ollama<br>
abo84 config set model aibradaa/abo84-beta<br>
<br>
# Verify configuration<br>
abo84 config list
                    </div>
                </div>
                <div class="step">
                    <div class="step-number">6</div>
                    <h3>Integrate with Desktop App</h3>
                    <p>Enable Ollama in the ABO-84 desktop application:</p>
                    <ol style="color:#A8B2CC;line-height:2">
                        <li>Open ABO-84 desktop app</li>
                        <li>Go to Settings ‚Üí Analysis Engine</li>
                        <li>Select "Ollama (Local)" from the dropdown</li>
                        <li>Click "Test Connection" to verify</li>
                        <li>Save settings</li>
                    </ol>
                    <div class="info-box">
                        <strong>üîÑ Automatic Fallback:</strong> If Ollama is unavailable, ABO-84 will automatically fall back to cloud analysis (requires internet).
                    </div>
                </div>
                <div class="step">
                    <div class="step-number">7</div>
                    <h3>Start Analyzing Offline</h3>
                    <p>You're now ready to analyze code completely offline:</p>
                    <div class="code-block">
# Analyze your project<br>
cd ~/projects/your-app<br>
abo84 analyze ./src<br>
<br>
# Watch mode with auto-fix<br>
abo84 watch ./src --auto-fix<br>
<br>
# Generate reports<br>
abo84 report --format=json > analysis.json
                    </div>
                    <p>All analysis happens locally with no network requests!</p>
                </div>
            </div>
        </section>
        <section style="max-width:900px;margin:60px auto;padding:0 20px">
            <div class="container">
                <h2 style="text-align:center;color:#fff;font-family:'Orbitron',sans-serif;font-size:2.5rem;margin-bottom:40px">Performance Tuning</h2>
                <div class="step">
                    <h3>GPU Acceleration</h3>
                    <p>For optimal performance, ensure GPU support is enabled:</p>
                    <div class="code-block">
# Check GPU availability<br>
ollama ps<br>
<br>
# NVIDIA GPU (Linux/Windows):<br>
# Ollama automatically uses CUDA if available<br>
<br>
# Apple Silicon (M1/M2/M3):<br>
# Automatically uses Metal acceleration
                    </div>
                    <p><strong>Performance expectations:</strong></p>
                    <ul style="color:#A8B2CC;line-height:2">
                        <li>With GPU: ~2-5 seconds per file</li>
                        <li>CPU only: ~10-20 seconds per file</li>
                        <li>Large projects (500+ files): Use incremental analysis</li>
                    </ul>
                </div>
                <div class="step">
                    <h3>Memory Management</h3>
                    <p>Adjust memory allocation for large codebases:</p>
                    <div class="code-block">
# Set maximum context window (default: 4096)<br>
abo84 config set ollama.contextLength 8192<br>
<br>
# Set batch size for large projects<br>
abo84 config set ollama.batchSize 50
                    </div>
                </div>
            </div>
        </section>
        <section style="max-width:900px;margin:60px auto;padding:0 20px">
            <div class="container">
                <h2 style="text-align:center;color:#fff;font-family:'Orbitron',sans-serif;font-size:2.5rem;margin-bottom:40px">Troubleshooting</h2>
                <div class="step">
                    <h3>"Model not found" error</h3>
                    <p>If you see this error, re-pull the model:</p>
                    <div class="code-block">
ollama rm aibradaa/abo84-beta<br>
ollama pull aibradaa/abo84-beta
                    </div>
                </div>
                <div class="step">
                    <h3>Slow analysis performance</h3>
                    <p>Common causes and solutions:</p>
                    <ul style="color:#A8B2CC;line-height:2">
                        <li>Insufficient RAM: Close other applications, or upgrade to 16GB+</li>
                        <li>No GPU: Performance is slower on CPU. Consider using cloud mode for large projects.</li>
                        <li>Large files: Enable incremental analysis: <code style="color:#00F0FF">abo84 config set incremental true</code></li>
                    </ul>
                </div>
                <div class="step">
                    <h3>Ollama service not running</h3>
                    <div class="code-block">
# Start Ollama service<br>
ollama serve<br>
<br>
# Or enable auto-start (systemd on Linux):<br>
sudo systemctl enable ollama<br>
sudo systemctl start ollama
                    </div>
                </div>
            </div>
        </section>
        <section style="padding:60px 20px;text-align:center">
            <div class="container">
                <h2 style="color:#fff;font-family:'Orbitron',sans-serif;font-size:2rem;margin-bottom:20px">Ready for 100% Private Code Analysis?</h2>
                <p style="color:#A8B2CC;margin-bottom:30px">Upgrade to Ultimate tier to access ABO-84 Ollama integration and analyze code completely offline.</p>
                <a href="/app.html#upgrade" class="btn btn-primary btn-large">Upgrade to Ultimate</a>
            </div>
        </section>
    </main>
    <footer class="site-footer">
        <div class="container">
            <div class="footer-bottom">
                <p class="footer-copyright">¬© 2025 AI Bradaa. All rights reserved.</p>
            </div>
        </div>
    </footer>
</body>
</html>
